{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following\n",
    "- Chapter 3. Step 3: Funcamentals of Machine Learning, [*Mastering Machine Learning with Python in Six Steps*][ml6s] (Copyright &copy; Manohar Swamynathan 2019)\n",
    "<!-- - https://github.com/Apress/mastering-ml-w-python-in-six-steps-2e (\n",
    "Copyright &copy; 2019 Manohar Swamynathan) -->\n",
    "\n",
    "---\n",
    "\n",
    "Machine Learning Perspective of Data\n",
    "====================================\n",
    "> *Data* is the facts and figures (can also be referred to as *raw data*) that we have available with respect to the business context. Data is made up of two aspects:\n",
    "> 1. *Objects* such as people, tree, animals, etc.\n",
    "> 2. *Attributes* that were recorded for objects such as age, size, weight, cost, etc.\n",
    "\n",
    "\n",
    "Feature Engineering\n",
    "===================\n",
    "Dealing with Missing Data\n",
    "-------------------------\n",
    "> Missing data can mislead or create problems for analyzing the data. In order to avoid any such issues, you need to impute missing data. There are four most commonly used techniques for data imputation:\n",
    "> - Delete\n",
    "> - Replace with the summary (*mean*, *mode* or *medan* for a respective column)\n",
    "> - Random replace\n",
    "> - Use a predictive model\n",
    "\n",
    "\n",
    "Handling Categorical Data\n",
    "-------------------------\n",
    "### Create a dummy varaible\n",
    "(Boolean) 1 for presence of a category, and 0 for absence. You should create *k*-1 dummy variables, where *k* is the number of levels.\n",
    "\n",
    "Scikit-learn provides a useful function, *One Hot Encoder*, to create a dummy variable for a given categorical variable.\n",
    "\n",
    "\n",
    "[ml6s]: https://doi.org/10.1007/978-1-4842-4947-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from patsy import dmatrices\n",
    "df = pd.DataFrame({'A': ['high', 'medium', 'low'],\n",
    "                    'B': [10,20,30]},\n",
    "                    index=[0, 1, 2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies = pd.get_dummies(df, prefix=\"A\", columns=['A'])\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to number\n",
    "Another simple method is to represent the text description of each level with a number by using the *Label Encoder* function of Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A_pd_factorized'] = pd.factorize(df['A'])[0]\n",
    "\n",
    "# Alternatively you can use sklearn's method LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['A_LabelEncoded'] = le.fit_transform(df.A)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mormalizing Data\n",
    "----------------\n",
    "> Bringing all the different types of variable units in the same order of magnitude eliminates the potential outlier measurements that would misrepresent the finding and negatively affect the accuracy of the conclusion. Two broadly used methods for rescaling data are *normaliztion* and *standardization*.\n",
    "\n",
    "> Normalizing data can be achieved by min-max scaling:\n",
    "\\begin{equation}\n",
    "X_\\text{normalized} = \\frac{X - X_\\text{min}}{X_\\text{max} - X_\\text{min}}\n",
    "\\end{equation}\n",
    ">> **Note**: Be sure to remove extreme outliers before applying the preceding technique, as it can skew the normal values in your data to a small interval.\n",
    "\n",
    "> The standardization technique will transform the variables to have *zero mean* and *standard deviation of one* (the outcome is commonly known as *z*-scores):\n",
    "\\begin{equation}\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "\\end{equation}\n",
    "> where $\\mu$ is the mean and $\\sigma$ the standard deviation.\n",
    "\n",
    "> Standardization often has been the preferred method for various analysis, as it tells us where each data point lies within its distribution and gives a rough indication of outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X_std = std_scale.transform(X)\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(X)\n",
    "X_minmax = minmax_scale.transform(X)\n",
    "\n",
    "print('Mean before standardization: petal length={:+.1f}, petal width={:+.1f}'.format(X[:, 0].mean(), X[:, 1].mean()))\n",
    "print(' SD  before standardization: petal length={:+.1f}, petal width={:+.1f}'.format(X[:, 0].std(), X[:, 1].std()))\n",
    "\n",
    "print('Mean after  standardization: petal length={:+.1f}, petal width={:+.1f}'.format(X_std[:, 0].mean(), X_std[:, 1].mean()))\n",
    "print(' SD  after  standardization: petal length={:+.1f}, petal width={:+.1f}'.format(X_std[:, 0].std(), X_std[:, 1].std()))\n",
    "\n",
    "print('\\nMin value before min-max scaling: petal length={:+.1f}, petal width={:+.1f}'.format(X[:, 0].min(), X[:, 1].min()))\n",
    "print('Max value before min-max scaling: petal length={:+.1f}, petal width={:+.1f}'.format(X[:, 0].max(), X[:, 1].max()))\n",
    "\n",
    "print('Min value after  min-max scaling: petal length={:+.1f}, petal width={:+.1f}'.format(X_minmax[:, 0].min(), X_minmax[:, 1].min()))\n",
    "print('Max value after  min-max scaling: petal length={:+.1f}, petal width={:+.1f}'.format(X_minmax[:, 0].max(), X_minmax[:, 1].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Construction or Genration\n",
    "---------------------------------\n",
    "### Exploratory Data Analysis\n",
    "> EDA is all about understanding your data by employing summarizing and visualizing techniques. At a high level, EDA can be performed in two ways:\n",
    "> - univariate analysis\n",
    "> - multivariate analysis\n",
    "\n",
    "![Iris: sepal and petal](https://thegoodpython.com/assets/images/iris-species.png)\n",
    "> The Iris dataset is a well-known dataset used extensively in pattern recognition literature. It is hosted at the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris/). The data set contains petal length, petal width, sepal length, and sepal width measurement for three types of Iris flowers: Setosa, Versicolor, and Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis\n",
    "> Individual variables are analyzed in isolation to get a better understanding of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ndarray to dataframe\n",
    "iris = pd.DataFrame(data = np.c_[iris['data'], iris['target']], columns = iris['feature_names'] + ['species'])\n",
    "\n",
    "# Replace the values with class labels\n",
    "iris.species = np.where(iris.species==0., 'setosa', np.where(iris.species==1., 'versicolor', 'virginica'))\n",
    "\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The columns 'species' is categorical, so let's check the frequency distribution for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-talk', 'seaborn-darkgrid'])\n",
    "title_sz = 14\n",
    "\n",
    "iris.hist()     # plot histogram\n",
    "plt.suptitle(\"Histogram\", fontsize=title_sz)  # add title to all subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "iris.boxplot()  # plot boxplot\n",
    "ax.set_title(\"Bar Plot\", fontsize=title_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean for each column by species\n",
    "iris_species_mean = iris.groupby(by=\"species\").mean()\n",
    "\n",
    "# Plot for mean of each feature for each label class\n",
    "iris_species_mean.plot(kind=\"bar\")\n",
    "\n",
    "plt.title(\"Class vs Measurements\", fontsize=title_sz)\n",
    "plt.ylabel(\"mean measurements (cm)\")\n",
    "plt.xticks(rotation=0)      # manage the xticks rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n",
    "> The correlation function uses a Pearson correlation coefficient, which results in a number between -1 to 1. A strong negative relationship is indicated by a coefficient closer to -1 and a strong positive correlation is indicated by a coefficient toward 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr = iris.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "plt.grid(which='major')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(iris, figsize=(12, 12))\n",
    "\n",
    "# Use suptitle to add title to all subplots\n",
    "plt.suptitle(\"Pair Plot\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning-Regression\n",
    "==============================\n",
    "> Let's consider a use case where we have collected students' average test grade scores and their respective average studied hours for the test from a group of similar IQ students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/Grade_Set_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple scatter plot\n",
    "df.plot(kind=\"scatter\", x=\"Hours_Studied\", y=\"Test_Grade\", title=\"Grade vs Hours Studied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Correlaton Matrix:\")\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation and Causation\n",
    "-------------------------\n",
    "> Although correlation helps us determine the degree of relationship between two or more variables, it does **not** tell us about the *cause and effect* relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a Slope\n",
    "---------------\n",
    "(The least square method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "# Create a linear regression object\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "x = df.Hours_Studied[:, np.newaxis]    # independent variable\n",
    "y = df.Test_Grade.values               # dependent variable\n",
    "\n",
    "# Train the model using the training sets\n",
    "lr.fit(x, y)\n",
    "print(\"Intercept:   \", lr.intercept_)\n",
    "print(\"Coefficient: \", lr.coef_)\n",
    "\n",
    "# Plot the fit line\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, lr.predict(x), linewidth=3)\n",
    "plt.title(\"Grade vs Hours Studied\")\n",
    "plt.ylabel(\"Test_Grade\")\n",
    "plt.xlabel(\"Hours_Studied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_i = 6.\n",
    "\n",
    "try:\n",
    "    k = float(input(\"Please assign the slope (k): \"))\n",
    "    b = float(input(\"Please assign the intercept (b): \"))\n",
    "    y_mp = k * x_i + b\n",
    "    # Manual prediction for a given value of x\n",
    "    print(\"Manual prediction:\", y_mp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Predict using the built-in function\n",
    "print(\"Using predict function:\", lr.predict([[x_i]])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Good Is Your Model?\n",
    "-----------------------\n",
    "> There are three metrics widely used for evaluating linear model performance:\n",
    "- R-Squared\n",
    "- Root Mean Squared Error\n",
    "- MAE\n",
    "\n",
    "### R-Squared for Goodness of fit\n",
    "> The *R-Squared* metric is the most popular practice of evaluating how well your model fits the data.\n",
    "\\begin{align}\n",
    "\\text{R-squared} =& \\frac{\\text{Total Sum of Square Residual}}{\\text{Sum of Square Total}} \\\\\n",
    "&= \\frac{\\sum_i (\\hat{y}_i - \\bar{y})^2}{\\sum_i (y_i - \\bar{y})^2} \\\\\n",
    "&\\in (0, 1]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### Root Mean Squared Error\n",
    "\\begin{equation}\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "\\end{equation}\n",
    "> One of the key properties of RMSE is that the unit will be the same as the target variable.\n",
    "\n",
    "### Mean Absolute Error\n",
    "\\begin{equation}\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to calculate r-squared, MAE, and RMSE\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Add the predict value to the dataframe\n",
    "y_p = lr.predict(x)\n",
    "df['Test_Grade_Pred'] = y_p\n",
    "y_m = np.mean(y)\n",
    "R = np.sum((y_p - y_m)**2) / np.sum((y - y_m)**2)\n",
    "print(\"R Squared using manual calculation:\", R)\n",
    "\n",
    "# Using built-in functions\n",
    "print(\"R Squared using built-in function:\", r2_score(df.Test_Grade, df.Test_Grade_Pred))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(df.Test_Grade, df.Test_Grade_Pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(df.Test_Grade, df.Test_Grade_Pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "> Let's introduce an *outlier*: a student has studied 5 hours and scored 100. Assume that this student has a higher IQ than others in the group. Notice the drop in R-Squared value. So it is important to apply business logic to avoid including outliers in the training data set, to generalize the model and increase accuray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add an outlier\n",
    "df.loc[9] = np.array([5, 100, np.nan])\n",
    "\n",
    "x = df.Hours_Studied[:, np.newaxis]    # independent variable\n",
    "y = df.Test_Grade.values               # dependent variable\n",
    "\n",
    "# Train the model using the training sets\n",
    "lr.fit(x, y)\n",
    "print(\"Intercept  :\", lr.intercept_)\n",
    "print(\"Coefficient:\", lr.coef_[0])\n",
    "\n",
    "# Manual prediction for a given value of x\n",
    "x_i = 6.\n",
    "\n",
    "try:\n",
    "    k = float(input(\"Please assign the slope (k): \"))\n",
    "    b = float(input(\"Please assign the intercept (b): \"))\n",
    "    y_mp = k * x_i + b\n",
    "    # Manual prediction for a given value of x\n",
    "    print(\"Manual prediction:\", y_mp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Predict using the built-in function\n",
    "print(\"Using predict function:\", lr.predict([[x_i]])[0])\n",
    "y_p = lr.predict(x)\n",
    "\n",
    "# Plot the fit line\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_p, lw=3)\n",
    "plt.title(\"Grade vs Hours Studied\")\n",
    "plt.xlabel(\"Hours_Studied\")\n",
    "plt.ylabel(\"Test_Grade\")\n",
    "\n",
    "# Add predict value to the dataframe\n",
    "df['Test_Grade_Pred'] = y_p\n",
    "\n",
    "# Using built-in functions\n",
    "print(\"R Squared:\", r2_score(df.Test_Grade, df.Test_Grade_Pred))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(df.Test_Grade, df.Test_Grade_Pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(df.Test_Grade, df.Test_Grade_Pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression\n",
    "---------------------\n",
    "> Essentially we'll be introducing higher order degree variables of the same independent variable in the equation.\n",
    "\n",
    "| Degree | Regression Equation |\n",
    "| - | :- |\n",
    "| Quadratic (2) | $Y = m_1 X + m_2 X^2 + c$ |\n",
    "| Cubic (3) | $Y = m_1 X + m_2 X^2 + m_3 X^3 + c$ |\n",
    "| $\\cdots$ | $\\cdots$ |\n",
    "| $N$th | $Y = m_1 X + m_2 X^2 + m_3 X^3 + \\cdots + m_n X^n + c$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 1000)    # 1000 sample numbers between -3 and 3\n",
    "\n",
    "# Plot subplots\n",
    "fig, ax = plt.subplots(2, 3)\n",
    "\n",
    "ax[0, 0].plot(x, x)\n",
    "ax[0, 0].set_title(\"linear\")\n",
    "ax[0, 1].plot(x, x**2)\n",
    "ax[0, 1].set_title(\"quadratic\")\n",
    "ax[0, 2].plot(x, x**3)\n",
    "ax[0, 2].set_title(\"cubic\")\n",
    "ax[1, 0].plot(x, x**4)\n",
    "ax[1, 0].set_title(\"degree 4\")\n",
    "ax[1, 1].plot(x, x**5)\n",
    "ax[1, 1].set_title(\"degree 5\")\n",
    "ax[1, 2].plot(x, x**6)\n",
    "ax[1, 2].set_title(\"degree 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let’s consider another set of students’ average test grade scores and their respective average studied hours for similar IQ students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/Grade_Set_2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the correlation between variables\n",
    "print(\"Correlation matrix:\")\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple scatter plot\n",
    "df.plot(kind=\"scatter\", x=\"Hours_Studied\", y=\"Test_Grade\", title=\"Grade vs Hours Studied\")\n",
    "\n",
    "# Create a linear regression object\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "x = df.Hours_Studied[:, np.newaxis]    # independent variable\n",
    "y = df.Test_Grade                      # dependent variable\n",
    "\n",
    "# Train the model using the training sets\n",
    "lr.fit(x, y)\n",
    "y_p = lr.predict(x)\n",
    "\n",
    "# Plot the fit line\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_p, lw=3)\n",
    "plt.title(\"Grade vs Hours Studied\")\n",
    "plt.xlabel(\"Hours_Studied\")\n",
    "plt.ylabel(\"Test_Grade\")\n",
    "\n",
    "print(\"R Squared:\", r2_score(y, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's try higher order polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = lm.LinearRegression()\n",
    "\n",
    "x = df.Hours_Studied\n",
    "y = df.Test_Grade\n",
    "\n",
    "# NumPy's vander method will return the Vandermonde matrix\n",
    "for deg in range(1, 6):\n",
    "    vdm = np.vander(x, deg+1)\n",
    "    lr.fit(vdm, y)\n",
    "    y_lr = lr.predict(vdm)\n",
    "    plt.plot(x, y_lr, label=f\"degree {deg}\")\n",
    "    plt.legend(loc=2)\n",
    "    print(f\"R-squared for degree {deg} = {r2_score(y, y_lr)}\")\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scikit-learn provides a function to generate a new feature matrix consisting of all polynomial combinations of the features with a degree less than or equal to the specified degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "x = df.Hours_Studied[:, np.newaxis]\n",
    "y = df.Test_Grade\n",
    "\n",
    "degree = 3\n",
    "model = make_pipeline(PolynomialFeatures(degree), lr)\n",
    "model.fit(x, y)\n",
    "y_p = model.predict(x)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_p)\n",
    "plt.title(\"Grade vs Hours Studied\")\n",
    "plt.xlabel(\"Hours_Studied\")\n",
    "plt.ylabel(\"Test_Grade\")\n",
    "\n",
    "print(\"R Squared using built-in function:\", r2_score(y, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Regression\n",
    "-----------------------\n",
    "> The equation take the following form:\n",
    "\\begin{equation}\n",
    "y = m_1 x_1 + m_2 x_2 + m_3 x_3 + \\cdots + m_n x_n,\n",
    "\\end{equation}\n",
    "> where each independent variable is represented by $x$'s, and $m$'s are the corresponding coefficients.\n",
    "\n",
    "> We'll be using the housing dataset, which contains sales prices of houses in the city of Windsor.\n",
    "\n",
    "| Variable Name | Description | Data Type |\n",
    "| ------------- | ----------- | --------- |\n",
    "| Price         | The sale price of a house | Numeric |\n",
    "| Lotsize       | The lot size of property in square feet | Numeric |\n",
    "| Bedrooms      | Number of Bedrooms        | Numeric |\n",
    "| Bathrms       | Number of full bathrooms  | Numeric |\n",
    "| Stories       | Number of stories excluding basement| Categorical |\n",
    "| Driveway      | Does the house have a driveway?     | Boolean/Categorical |\n",
    "| Recroom       | Does the house have a recreational room? | Boolean/Categorical |\n",
    "| Gashw         | Does the house use gas for hot water heating? | Boolean/Categorical |\n",
    "| Airco         | Does the house have central air conditioning? | Boolean/Categorical |\n",
    "| Garagepl      | Number of garage places   | Numeric |\n",
    "| Prefarea      | Is the house located in the preferred neighborhood of the city?   | Boolean/Categorical |\n",
    "\n",
    "> Let’s build a model to predict the house price (dependent variable) by considering the rest of the variables as independent variables. The categorical variables need to be handled appropriately before running the first iteration of the model. `Scikit-learn` provides useful built-in preprocessing functions to handle categorical variables.\n",
    "> - *LabelBinarizer*: This will replace the binary variable text with numeric values. We’ll be using this function for the binary categorical variables.\n",
    "> - *LabelEncoder*: This will replace category level with number representation.\n",
    "> - *OneHotEncoder*: This will convert $n$ levels to an $n-1$ new variable, and the new variables will use 1 to indicate the presence of level and 0 for otherwise. Note that before calling `OneHotEncoder`, we should use LabelEncoder to convert levels to the number. Alternatively, we can achieve the same using the `get_dummies` of the `Pandas` package. This is more efficient to use, as we can directly use it on the column with text description without having to convert to numbers first.\n",
    "\n",
    "\n",
    "#### Multicollinearity and Variation Inflation Factor\n",
    "> Multicollinearity is an incident where one or more of the independent variables are strongly correlated with each other. In such an incident, we should use only one among correlated independent variables.\n",
    "\n",
    "> The standard guideline for Variance Inflation Factor (VIF) value is: VIF = 1 means no correlation exists, and VIF > 1 but < 5 means moderate correation exists.\n",
    "\\begin{equation}\n",
    "\\text{VIF}_i = \\frac{1}{1 - R_i^2}\n",
    "\\end{equation}\n",
    "where $R_i^2$ is the coefficient of determination of variable $X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/Housing_Modified.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary fields to numeric boolean fields\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "df.driveway = lb.fit_transform(df.driveway)\n",
    "df.recroom = lb.fit_transform(df.recroom)\n",
    "df.fullbase = lb.fit_transform(df.fullbase)\n",
    "df.gashw = lb.fit_transform(df.gashw)\n",
    "df.airco = lb.fit_transform(df.airco)\n",
    "df.prefarea = lb.fit_transform(df.prefarea)\n",
    "\n",
    "# Create dummy variables for stories\n",
    "df_stories = pd.get_dummies(df['stories'], prefix=\"stories\", drop_first=True)\n",
    "\n",
    "# Join the dummy variables to the main dataframe\n",
    "df = pd.concat([df, df_stories], axis=1)\n",
    "del df['stories']\n",
    "\n",
    "# Plot the correlation matrix using statsmodels graphics' plot_corr\n",
    "# Create correlation matrix\n",
    "corr = df.corr()\n",
    "sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see from the plot that `stories_one` has a strong negative correlation with `stories_two`. Let’s perform the VIF analysis to eliminate strongly correlated independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor, OLSInfluence\n",
    "\n",
    "# Create a Python list of feature names\n",
    "dependent_variable = 'price'\n",
    "l = df.keys().tolist()\n",
    "l.remove(dependent_variable)\n",
    "independent_variables = l\n",
    "\n",
    "# Select the subset\n",
    "X = df[independent_variables]\n",
    "y = df[dependent_variable]\n",
    "\n",
    "thresh = 10\n",
    "\n",
    "for i in np.arange(ncol := len(independent_variables)):\n",
    "    vif = [variance_inflation_factor(X[independent_variables].values,\n",
    "           ix) for ix in range(ncol)]\n",
    "    if (mvif := max(vif)) > thresh:\n",
    "        max_ind = vif.index(mvif)\n",
    "        print(f\"{vif = }\\n\")\n",
    "        print(f\"dropping '{X[independent_variables].columns[max_ind]}' at index: {str(max_ind)}\")\n",
    "        independent_variables.pop(max_ind)\n",
    "        ncol = len(independent_variables)\n",
    "    else:\n",
    "        break\n",
    "print(\"Final variables:\", independent_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The previous VIF analysis has eliminated bedrooms greater than 10; however, stories_one and stories_two have been retained.\n",
    "> Let's run the first iteration of a multivariate regression model with the set of independent variables that have passed the VIF analysis.\n",
    "> To test the model performance, the common practice is to split the data set into 80/20 (or 70/30) for train/test, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Inherit the list of feature names\n",
    "independent_variables = l\n",
    "\n",
    "# Select the subset\n",
    "X = df[independent_variables]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=1)\n",
    "\n",
    "# Build the model\n",
    "lm = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "print(lm.summary())\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_train_pred = lm.predict(X_train)\n",
    "y_test_pred = lm.predict(X_test)\n",
    "y_pred = lm.predict(X)\n",
    "\n",
    "print(\"Train MAE :\", metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "print(\"Test  MAE :\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test  RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Diagnostics\n",
    "> There are a set of procedures and assumptions that need to be verified about our model results, otherwise the model could be misleading. Let's look at some of the important regression diagnostics.\n",
    "\n",
    "#### Outliers\n",
    "> Data points that are far away from the fitted regression line are called *outliers*. Plotting normalized residual vs. leverage will give us a good understanding of the outlier's points. *Residual* is the difference between actual vs. predicted, and *leverage* is a measure of how far away the independent variable values of observation are from those of the other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig = plot_leverage_resid2(lm, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Running a Bonferroni outlier test will give us $p$-values for each observation, and those observations with $p < 0.05$ are the outliers affecting the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bonferroni outlier test\n",
    "test = lm.outlier_test()\n",
    "\n",
    "print(\"Bad data points [bonf(p) < 0.05]:\")\n",
    "test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homoscedasticity and Normallity\n",
    "> The error variance should be constant, which is known as *homoscedasticity*, and the error should be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check homoscedasticity\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "ax1.plot(lm.resid, 'o')\n",
    "ax1.set_title(\"Residual Plot\")\n",
    "ax1.set_xlabel(\"Observation Numbers\")\n",
    "ax1.set_ylabel(\"Residual\")\n",
    "\n",
    "ax2.hist(lm.resid, density=True)\n",
    "ax2.set_title(\"Error Normality Plot\")\n",
    "ax2.set_xlabel(\"Residual\")\n",
    "ax2.set_ylabel(\"Observation Numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The relationships between the predictors and the outcome variable should be linear. If the relationship is not linear then appropriate transformation (such as log, square root, and higher order polynomials, etc.) should be applied to the dependent/independent variable to fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity plots\n",
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "fig = sm.graphics.plot_partregress_grid(lm, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting and Underfitting\n",
    "> *Underfitting* occurs when the model does not fit the data well and is unable to capture the underlying trend in it. In this case, we can notice a low accuracy in training and test data set.\n",
    "\n",
    "> *Overfitting* occurs when the model fits the data too well, capturing all the noises. In this case, we can notice a high accuracy in the training data set, whereas the same model will result in a low accuracy on the test data set.\n",
    "\n",
    "\n",
    "Regularization\n",
    "--------------\n",
    "> With the increase in a number of variables and the increase in model complexity, the probability of overfitting also increases. Regularization is a technique to avoid the **overfitting** problem.\n",
    "\n",
    "> *LASSO*: This provides a sparse solution, also known as *L1 regularization*. It guides parameter value to be zero (i.e., the coefficients of the variables that add minor value to the model will be zero), and adds a penalty equivalent to the absolute value of the magnitude of coefficients.\n",
    "\n",
    "> *Ridge regression*: Also known as *Tikhonov (L2) regularization*. It guides parameters to be close to zero but not zero. You can use this when you have many variables that add minor value to the model accuracy individually, however overall improve the model accuracy and cannot be excluded from the model. Ridge regression will apply a penalty to reduce the magnitude of the coefficient of all variables that add minor value to the model accuracy, adding penalty equivalent to the square of the magnitude of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/Grade_Set_2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns = ['x', 'y']\n",
    "\n",
    "for i in range(2, 50):      # power of 1 is already there\n",
    "    colname = f'x_{i}'      # new colname will be x_power\n",
    "    df[colname] = df['x']**i\n",
    "\n",
    "independent_variables = list(df.columns)\n",
    "independent_variables.remove('y')\n",
    "\n",
    "X = df[independent_variables]\n",
    "y = df.y\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=1)\n",
    "\n",
    "# Ridge regression\n",
    "lr = linear_model.Ridge(alpha=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"-\" * 5 + \" Ridge Regression \" + \"-\" * 5)\n",
    "print(\"Train MAE :\", metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "print(\"Test  MAE :\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test  RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Ridge Coef:\")\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LASSO regression\n",
    "lr = linear_model.Lasso(alpha=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"-\" * 5 + \" LASSO Regression \" + \"-\" * 5)\n",
    "print(\"Train MAE :\", metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "print(\"Test  MAE :\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test  RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Ridge Coef:\")\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinear Regression\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x= np.array([-2, -1.64, -0.7, 0, 0.45, 1.2, 1.64, 2.32, 2.9])\n",
    "y = np.array([1.0, 1.5, 2.4, 2.0, 1.49, 1.2, 1.3, 1.2, 0.5])\n",
    "\n",
    "# Function for non-linear curve fitting\n",
    "def func(x, p1, p2):\n",
    "    return p1 * np.sin(p2 * x) + p2 * np.cos(p1 * x)\n",
    "\n",
    "popt, pcov = curve_fit(func, x, y, p0=(1.0, 0.2))\n",
    "\n",
    "p1 = popt[0]\n",
    "p2 = popt[1]\n",
    "residuals = y - func(x, p1, p2)\n",
    "fres = sum(residuals**2)\n",
    "\n",
    "curvex = np.linspace(-2, 3, 100)\n",
    "curvey = func(curvex, p1, p2)\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.plot(curvex, curvey)\n",
    "plt.title(\"Non-linear fitting\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(['data', 'fit'], loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitb790c22c1a684c1eac40ecab49941293"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

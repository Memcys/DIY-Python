{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning with Scikit-learn\n",
    "![Machine Learning Flow](https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![scikit-learn](https://scikit-learn.org/stable/_images/scikit-learn-logo-notext.png)](https://scikit-learn.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['seaborn-darkgrid', 'seaborn-notebook'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - In machine learning, the process of fitting a model or an algorithm to observed data is known as *training*.\n",
    "> - Machine-learning applications can often be classified into either of two types: *supervised* and *unsupervised learning*.\n",
    ">   - In *supervised learning*, the data includes feature variables and known response variables.\n",
    ">   - In contrast, *unsupervised learning* corresponds to situations where machine-learning applications are trained with raw data that is not labeled or otherwise manually prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning\n",
    "===================\n",
    "Regression\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all, y_all = datasets.make_regression(n_samples=50, n_features=50, n_informative=10)\n",
    "print(f\"{X_all = }\\n{y_all = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{X_all.shape = }\\n{y_all.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X_all, y_all, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "$$\n",
    "\\min_\\beta \\lVert X \\beta - y \\rVert_2^2\n",
    "$$\n",
    "where $X$ is the feature matreix, $y$ the response variables, and $\\beta$ the vector of model parameters and where $\\lVert \\cdot \\rVert_2$ denotes the $L_2$ norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(resid):\n",
    "    \"\"\"return the sum of squared errors\"\"\"\n",
    "    return np.sum(resid**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print(f\"{sse_train = }\\n{sse_test  = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{model.score(X_train, y_train) = }\\n{model.score(X_test,  y_test) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals_and_coeff(resid_train, resid_test, coeff):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "    axes[0].bar(np.arange(len(resid_train)), resid_train)\n",
    "    axes[0].set_xlabel(\"sample number\")\n",
    "    axes[0].set_ylabel(\"residual\")\n",
    "    axes[0].set_title(\"training data\")\n",
    "    axes[1].bar(np.arange(len(resid_test)), resid_test)\n",
    "    axes[1].set_xlabel(\"sample number\")\n",
    "    axes[1].set_ylabel(\"residual\")\n",
    "    axes[1].set_title(\"testing data\")\n",
    "    axes[2].bar(np.arange(len(coeff)), coeff)\n",
    "    axes[2].set_xlabel(\"coefficient number\")\n",
    "    axes[2].set_ylabel(\"coefficient\")\n",
    "    fig.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized regression\n",
    "- LASSO regression\n",
    "$$\n",
    "\\min_\\beta \\left\\{ \\lVert X \\beta - y \\rVert_2^2 + \\alpha \\lVert \\beta \\rVert_1 \\right\\}\n",
    "$$\n",
    "- Ridge regression\n",
    "$$\n",
    "\\min_\\beta \\left\\{ \\lVert X \\beta - y \\rVert_2^2 + \\alpha \\lVert \\beta \\rVert_2^2 \\right\\}\n",
    "$$\n",
    "- Elastic-net regularization\n",
    "$$\n",
    "\\min_\\beta \\left\\{ \\lVert X \\beta - y \\rVert_2^2 + \\alpha \\rho \\lVert \\beta \\rVert_1 + \\alpha(1 - \\rho) \\lVert \\beta \\rVert_2^2 \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the model\n",
    "model = linear_model.Ridge(alpha=2.5)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the trained model\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print(f\"{sse_train = }\\n{sse_test  = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the model\n",
    "model = linear_model.Lasso(alpha=1.0)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the trained model\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print(f\"{sse_train = }\\n{sse_test  = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the regression model parameters and the SSE for the training and testing datasets depend on the value of Î± for a specific problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-4, 2, 100)\n",
    "coeffs = np.zeros((len(alphas), X_train.shape[1]))\n",
    "sse_train = np.zeros_like(alphas)\n",
    "sse_test = np.zeros_like(alphas)\n",
    "\n",
    "for n, alpha in enumerate(alphas):\n",
    "    model = linear_model.Lasso(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    coeffs[n, :] = model.coef_\n",
    "    sse_train[n] = sse(y_train - model.predict(X_train))\n",
    "    sse_test[n] = sse(y_test - model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "for n in range(coeffs.shape[1]):\n",
    "    axes[0].plot(np.log10(alphas), coeffs[:, n], color=\"k\", lw=0.5)\n",
    "\n",
    "axes[1].semilogy(np.log10(alphas), sse_train, label=\"train\")\n",
    "axes[1].semilogy(np.log10(alphas), sse_test, label=\"test\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[0].set_xlabel(r\"$\\log_{10} \\alpha$\")\n",
    "axes[0].set_ylabel(r\"coefficients\")\n",
    "axes[1].set_xlabel(r\"$\\log_{10} \\alpha$\")\n",
    "axes[1].set_ylabel(\"sse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation\n",
    "> Testing several values of $\\alpha$ automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LassoCV()\n",
    "model.fit(X_all, y_all)\n",
    "model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print(f\"{sse_train = }\\n{sse_test  = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic-net regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.ElasticNetCV()\n",
    "model.fit(X_train, y_train)\n",
    "model.alpha_, model.l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print(f\"{sse_train = }\\n{sse_test  = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification\n",
    "--------------\n",
    "- logistic regression\n",
    "- nearest neighbor method\n",
    "- support vector machine\n",
    "- decision tree\n",
    "- Random Forest method\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{iris.target_names = }\\n{iris.target.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Iris: sepal and petal](https://thegoodpython.com/assets/images/iris-species.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{iris.feature_names = }\\n{iris.data.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(iris.data, iris.target, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *confusion matrix*, the element $C_{ij}$ corresponds to the number of samples of category $i$ that were categorized as $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_vec = np.linspace(0.1, 0.9, 30)\n",
    "classifiers = [\n",
    "    tree.DecisionTreeClassifier,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    svm.SVC,\n",
    "    ensemble.RandomForestClassifier\n",
    "]\n",
    "cm_diags = np.zeros((3, len(train_size_vec), len(classifiers)), dtype=float)\n",
    "\n",
    "for n, train_size in enumerate(train_size_vec):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        model_selection.train_test_split(iris.data, iris.target,\n",
    "                                         train_size=train_size)\n",
    "    for m, Classifier in enumerate(classifiers):\n",
    "        classifier = Classifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_test_p = classifier.predict(X_test)\n",
    "        cm_diags[:, n, m] = metrics.confusion_matrix(y_test, y_test_p).diagonal()\n",
    "        cm_diags[:, n, m] /= np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(classifiers), figsize=(12, 3))\n",
    "\n",
    "for m, Classifier in enumerate(classifiers):\n",
    "    for l in range(len(iris.target_names)):\n",
    "        axes[m].plot(train_size_vec, cm_diags[l, :, m], label=iris.target_names[l])\n",
    "    axes[m].set_title(type(Classifier()).__name__)\n",
    "    axes[m].set_ylim(0, 1.1)\n",
    "    axes[m].set_ylabel(\"classification accuracy\")\n",
    "    axes[m].set_xlabel(\"training size ratio\")\n",
    "    axes[m].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning\n",
    "=====================\n",
    "- K-means\n",
    "- mean-shift\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "n_clusters = 3\n",
    "clustering = cluster.KMeans(n_clusters=n_clusters)\n",
    "clustering.fit(X)\n",
    "\n",
    "y_pred = clustering.predict(X)\n",
    "y_pred[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_0, idx_1, idx_2 = (np.where(y_pred == n) for n in range(3))\n",
    "y_pred[idx_0], y_pred[idx_1], y_pred[idx_2] = eval(input(\"index of 0, 1, 2 in y_pred:\\n\"))\n",
    "y_pred[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[idx_1], y[idx_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[1]\n",
    "\n",
    "fig, axes = plt.subplots(N, N, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "colors = [\"coral\", \"blue\", \"green\"]\n",
    "markers = [\"^\", \"v\", \"o\"]\n",
    "\n",
    "for m in range(N):\n",
    "    for n in range(N):\n",
    "        for p in range(n_clusters):\n",
    "            mask = y_pred == p\n",
    "            axes[m, n].scatter(X[:, m][mask], X[:, n][mask], s=30, marker=markers[p], color=colors[p], alpha=0.25)\n",
    "        for idx in np.where(y != y_pred):\n",
    "            axes[m, n].scatter(X[idx, m], X[idx, n], s=30, marker=\"s\", edgecolor=\"red\", facecolor=(1, 1, 1, 0))\n",
    "            axes[N-1, m].set_xlabel(iris.feature_names[m])\n",
    "            axes[m, 0].set_ylabel(iris.feature_names[m])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitb790c22c1a684c1eac40ecab49941293"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
